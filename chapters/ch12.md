# Résumé.

We present a machine learning experiment where we attempted to classify lung nodules as benign or malignant based on CT scan images. We used a convolutional neural network (CNN) model and trained it on a dataset of 10861 nodules, of which only 25 were malignant. We evaluated the model on a validation set of 2709 nodules, of which only 6 were malignant. We obtained an accuracy of 89%, but a recall of 0% for the malignant class. We discuss the reasons for this poor performance and suggest some possible solutions to address the class imbalance problem.

# Introduction

Lung cancer is one of the leading causes of cancer-related deaths worldwide. Early detection and diagnosis of lung nodules, which are small masses of tissue in the lungs, can improve the survival rate and treatment outcomes for lung cancer patients. However, lung nodules are difficult to detect and classify, as they can vary in size, shape, location, and appearance. Moreover, most lung nodules are benign, meaning they are not cancerous, and only a small fraction are malignant, meaning they are cancerous. This poses a challenge for machine learning models that aim to automate the task of lung nodule detection and classification.

In this rapport, we present a machine learning experiment where we used a CNN model to classify lung nodules as benign or malignant based on CT scan images. We used a publicly available dataset called LUNA16, which contains 888 CT scans with annotated nodules. We extracted 10861 nodules from the scans, of which only 25 were malignant. We split the nodules into a training set of 8152 nodules and a validation set of 2709 nodules. We trained the CNN model on the training set and evaluated it on the validation set. We measured the performance of the model using accuracy and recall.

# How to read, process, and visualize CT scans with lung nodules

To read, process, and visualize CT scans with lung nodules, we used two Python libraries: SimpleITK and matplotlib. SimpleITK is a library that provides a simplified interface to the Insight Segmentation and Registration Toolkit (ITK) , which is a framework for image analysis and processing. Matplotlib is a library that provides capabilities for image visualization and enhancement .

We used SimpleITK to read the CT scan files from the LUNA16 dataset , which are in DICOM or NIfTI format, and convert them into numpy arrays, which are multidimensional arrays of numbers that can be easily manipulated and analyzed. We also used SimpleITK to get the origin and spacing of the images, which are the coordinates and voxel size of the images. We then used SimpleITK to resample the images with a uniform voxel size of 1 mm x 1 mm x 1 mm, normalize the pixel values to the range of -1000 to 1000 Hounsfield units (HU), and apply a lung segmentation algorithm to extract the lung regions from the images.

We used matplotlib to plot and show the CT scan slices that contain nodules. We also used matplotlib to draw white lines around each nodule to highlight its location and size. We used a function that takes as input a CT scan array, a numpy array of nodules coordinates and diameters, the origin and spacing of the image, and some optional parameters. The function loops over the nodules array and calculates the voxel coordinates of each nodule based on its physical coordinates and the origin and spacing of the image. It then modifies the CT scan array by drawing white lines around each nodule. It finally plots and shows the CT scan slices that contain nodules using matplotlib.

Figure 1 shows an example of a CT scan slice with a nodule highlighted by white lines.

![Figure 1: Examples of a CT scan slice with a nodule highlighted by white lines](images/seg4.png)


# Method

## Materials

The materials used in this study were CT scans and annotations from the LUNA16 dataset . The LUNA16 dataset is a publicly available collection of CT scans from the Lung Image Database Consortium (LIDC) and Image Database Resource Initiative (IDRI) . The dataset contains 888 CT scans with a slice thickness of less than 3 mm and a pixel spacing of less than 0.7 mm. The dataset also provides two separate CSV files that contain information about the candidates and the annotations.

The candidates.csv file has four columns: seriesuid, coordX, coordY, coordZ, and class, where seriesuid is the unique identifier of each scan, coordX, coordY, and coordZ are the spatial coordinates of each candidate in millimeters, and class is a binary label indicating whether the candidate is a nodule (1) or not (0). The annotations.csv file has five columns: seriesuid, coordX, coordY, coordZ, and diameter_mm, where seriesuid is the unique identifier of each scan, coordX, coordY, and coordZ are the spatial coordinates of each annotation in millimeters,
and diameter_mm is the diameter of each annotation in millimeters. The annotations are based on manual markings by four radiologists who independently reviewed each scan and identified nodules larger than 3 mm in diameter.

## Procedure

The procedure of this study consisted of three main steps: data preprocessing, nodule detection algorithm development, and performance evaluation.

### Data preprocessing

The data preprocessing step involved converting the CT scans from DICOM format to arrays(tensor), resampling the scans to a uniform voxel size of 1 mm x 1 mm x 1 mm, normalizing the pixel values to the range of -1000 to 320 Hounsfield units (HU), and applying a lung segmentation algorithm to extract the lung regions from the scans. The lung segmentation algorithm was based on a combination of thresholding, morphological operations, and connected component analysis . The output of this step was a set of lung masks for each scan.

### Nodule detection algorithm development

The process of developing the nodule detection algorithm involved several critical steps. At its core, the algorithm was designed around a Convolutional Neural Network (CNN) model, created to detect nodules from Computed Tomography (CT) scans.

The model's architecture was constructed as follows:

- The **Input Layer** was designed to take in a 3D grayscale image.
- The first convolutional layer, **Convolutional Layer 1**, was equipped with 32 filters and a 3x3x3 kernel size. Padding was set to 1 to maintain the spatial dimensions of the input.
- The output from the first convolutional layer was passed through a **ReLU (Rectified Linear Unit) Activation Function**, referred to as **Activation Layer 1**.
- The second convolutional layer, **Convolutional Layer 2**, was also designed with 32 filters and a 3x3x3 kernel size, with padding set to 1.
- The output from the second convolutional layer was processed through another ReLU activation function, **Activation Layer 2**.
- A 3D max pooling operation was applied in **Max Pooling Layer 1** with a 2x2x2 kernel and stride of 2, reducing the spatial dimensions by half.
- The structure was repeated with **Convolutional Layer 3 and 4**, **Activation Layer 3 and 4**, and **Max Pooling Layer 2**, but this time the convolutional layers were equipped with 64 filters.
- The output from the final max pooling layer was flattened into a 1D tensor in the **Flatten Layer** before being passed to the fully connected layer using the `view` method in PyTorch.
- The flattened tensor was then processed through a fully connected (dense) layer, known as the **Fully Connected Layer**. This layer was designed with two output neurons, corresponding to the two classes (presence or absence of nodules).
- Finally, a softmax function was applied to the output of the fully connected layer in the **Softmax Layer**. This step is standard for binary classification tasks, providing a probability distribution over the two classes.

The model was trained using the Adam optimizer, with a learning rate of 0.001, a batch size of 40, and a binary cross-entropy loss function. Training was conducted over 100 epochs .

To optimize the model, a grid search method was utilized to find the best combination of hyperparameters, including the number of filters, kernel size, dropout rate, and weight decay.

# Results
## Model Performance: Training and Validation Accuracy

The model's performance was evaluated based on its accuracy on the training and validation datasets. The accuracy of the model on the training data and the validation data is recorded for each epoch during the training process.

The *accuracy* values represent the model's ability to correctly predict the outcome on the training data, while *validation accuracy* values represent the model's ability to generalize its predictions to unseen data (validation data).

Observing the accuracy and validation accuracy values over the epochs, we can see that the model is learning as there is a steady improvement in both the training and validation accuracies. The model starts with lower accuracies around 0.64 and improves to above 0.89 by the end of training, which indicates that the model has learned to correctly classify a high proportion of cases.


However, We obtained an accuracy of 89% on the validation set, which means that the model correctly predicted the class of 2654 out of 2709 nodules.

## Model Evaluation: Precision, Recall, and F1-Score

In addition to accuracy, the model's performance was also evaluated using *precision*, *recall*, and *F1-score*. These metrics provide a more comprehensive view of the model's performance, particularly in cases where the classes are imbalanced.

- *Precision* is the proportion of true positive predictions (i.e., the model correctly identified a nodule) out of all positive predictions made by the model. A high precision indicates a low false positive rate. The model achieved a precision of 0.91 for class 0 and 0.86 for class 1.

- *Recall*, also known as sensitivity or true positive rate, is the proportion of true positive predictions out of all actual positives. A high recall indicates that the model correctly identified a large number of actual positive cases. The model achieved a recall of 0.91 for class 0 and 0.86 for class 1.

- *F1-score* is the harmonic mean of precision and recall, providing a single metric that balances both considerations. The model achieved an F1-score of 0.91 for class 0 and 0.86 for class 1.

These results indicate that the model performed well in identifying both classes, with a slight advantage in identifying class 0 (no nodule) over class 1 (nodule present). Overall, the model's performance in terms of precision, recall, and F1-score is commendable.


# Discussion

The main reason to prevent performance optimization is that we have an imbalance problem in our dataset. The dataset has a very large imbalance between the benign and malignant classes, with the benign class being over 400 times more frequent than the malignant class. This makes it hard for the model to learn how to distinguish between the classes, and it might default to predicting the most common class. Moreover, because our dataset is highly imbalanced, accuracy is not a good measure of performance, as it can be misleadingly high even when the model makes incorrect predictions for the minority class.

To address this problem, we need to use a better strategy to train our model and also a better indication of model performance instead of accuracy. Some possible solutions are:

- Using data augmentation techniques to increase the number of malignant samples in our dataset.
- Using oversampling or undersampling methods to balance the classes in our dataset.

We plan to implement some of these solutions in our future work and hope to improve our model's performance on lung nodule classification.

# Conclusion

We presented a machine learning experiment where we attempted to classify lung nodules as benign or malignant based on CT scan images. We used a CNN model and trained it on a dataset of 10861 nodules, of which only 25 were malignant. We evaluated the model on a validation set of 2709 nodules, of which only 6 were malignant. We obtained an accuracy of 89%, And We discussed the reasons to prevent performance optimization and suggested some possible solutions to address the class imbalance problem.
