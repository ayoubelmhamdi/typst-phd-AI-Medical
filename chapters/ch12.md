# Résumé.

We present a machine learning experiment where we attempted to classify lung nodules as benign or malignant based on CT scan images. We used a convolutional neural network (CNN) model and trained it on a dataset of 10861 nodules, of which only 25 were malignant. We evaluated the model on a validation set of 2709 nodules, of which only 6 were malignant. We obtained an accuracy of 99.78%, but a recall of 0% for the malignant class. We discuss the reasons for this poor performance and suggest some possible solutions to address the class imbalance problem.

# Introduction

Lung cancer is one of the leading causes of cancer-related deaths worldwide. Early detection and diagnosis of lung nodules, which are small masses of tissue in the lungs, can improve the survival rate and treatment outcomes for lung cancer patients. However, lung nodules are difficult to detect and classify, as they can vary in size, shape, location, and appearance. Moreover, most lung nodules are benign, meaning they are not cancerous, and only a small fraction are malignant, meaning they are cancerous. This poses a challenge for machine learning models that aim to automate the task of lung nodule detection and classification.

In this rapport, we present a machine learning experiment where we used a CNN model to classify lung nodules as benign or malignant based on CT scan images. We used a publicly available dataset called LUNA16, which contains 888 CT scans with annotated nodules. We extracted 10861 nodules from the scans, of which only 25 were malignant. We split the nodules into a training set of 8152 nodules and a validation set of 2709 nodules. We trained the CNN model on the training set and evaluated it on the validation set. We measured the performance of the model using accuracy and recall.

# How to read, process, and visualize CT scans with lung nodules

To read, process, and visualize CT scans with lung nodules, we used two Python libraries: SimpleITK and matplotlib. SimpleITK is a library that provides a simplified interface to the Insight Segmentation and Registration Toolkit (ITK) , which is a framework for image analysis and processing. Matplotlib is a library that provides capabilities for image visualization and enhancement .

We used SimpleITK to read the CT scan files from the LUNA16 dataset , which are in DICOM or NIfTI format, and convert them into numpy arrays, which are multidimensional arrays of numbers that can be easily manipulated and analyzed. We also used SimpleITK to get the origin and spacing of the images, which are the coordinates and voxel size of the images. We then used SimpleITK to resample the images with a uniform voxel size of 1 mm x 1 mm x 1 mm, normalize the pixel values to the range of -1000 to 1000 Hounsfield units (HU), and apply a lung segmentation algorithm to extract the lung regions from the images.

We used matplotlib to plot and show the CT scan slices that contain nodules. We also used matplotlib to draw white lines around each nodule to highlight its location and size. We used a function that takes as input a CT scan array, a numpy array of nodules coordinates and diameters, the origin and spacing of the image, and some optional parameters. The function loops over the nodules array and calculates the voxel coordinates of each nodule based on its physical coordinates and the origin and spacing of the image. It then modifies the CT scan array by drawing white lines around each nodule. It finally plots and shows the CT scan slices that contain nodules using matplotlib.

Figure 1 shows an example of a CT scan slice with a nodule highlighted by white lines.

![Figure 1: Examples of a CT scan slice with a nodule highlighted by white lines](images/seg4.png)


# Method

## Materials

The materials used in this study were CT scans and annotations from the LUNA16 dataset . The LUNA16 dataset is a publicly available collection of CT scans from the Lung Image Database Consortium (LIDC) and Image Database Resource Initiative (IDRI) . The dataset contains 888 CT scans with a slice thickness of less than 3 mm and a pixel spacing of less than 0.7 mm. The dataset also provides two separate CSV files that contain information about the candidates and the annotations.

The candidates.csv file has four columns: seriesuid, coordX, coordY, coordZ, and class, where seriesuid is the unique identifier of each scan, coordX, coordY, and coordZ are the spatial coordinates of each candidate in millimeters, and class is a binary label indicating whether the candidate is a nodule (1) or not (0). The annotations.csv file has five columns: seriesuid, coordX, coordY, coordZ, and diameter_mm, where seriesuid is the unique identifier of each scan, coordX, coordY, and coordZ are the spatial coordinates of each annotation in millimeters,
and diameter_mm is the diameter of each annotation in millimeters. The annotations are based on manual markings by four radiologists who independently reviewed each scan and identified nodules larger than 3 mm in diameter.

## Procedure

The procedure of this study consisted of three main steps: data preprocessing, nodule detection algorithm development, and performance evaluation using Recall.

### Data preprocessing

The data preprocessing step involved converting the CT scans from DICOM format to pytorch tensor, resampling the scans to a uniform voxel size of 1 mm x 1 mm x 1 mm, normalizing the pixel values to the range of -1000 to 1000 Hounsfield units (HU), and applying a lung segmentation algorithm to extract the lung regions from the scans. The lung segmentation algorithm was based on a combination of thresholding, morphological operations, and connected component analysis . The output of this step was a set of lung masks for each scan.

### Nodule detection algorithm development

The process of developing the nodule detection algorithm involved several critical steps. At its core, the algorithm was designed around a Convolutional Neural Network (CNN) model, created to detect nodules from Computed Tomography (CT) scans. This was implemented using the PyTorch machine learning framework.

The model's architecture was constructed as follows:

- The **Input Layer** was designed to take in a 3D grayscale image.
- The first convolutional layer, **Convolutional Layer 1**, was equipped with 32 filters and a 3x3x3 kernel size. Padding was set to 1 to maintain the spatial dimensions of the input.
- The output from the first convolutional layer was passed through a **ReLU (Rectified Linear Unit) Activation Function**, referred to as **Activation Layer 1**.
- The second convolutional layer, **Convolutional Layer 2**, was also designed with 32 filters and a 3x3x3 kernel size, with padding set to 1.
- The output from the second convolutional layer was processed through another ReLU activation function, **Activation Layer 2**.
- A 3D max pooling operation was applied in **Max Pooling Layer 1** with a 2x2x2 kernel and stride of 2, reducing the spatial dimensions by half.
- The structure was repeated with **Convolutional Layer 3 and 4**, **Activation Layer 3 and 4**, and **Max Pooling Layer 2**, but this time the convolutional layers were equipped with 64 filters.
- The output from the final max pooling layer was flattened into a 1D tensor in the **Flatten Layer** before being passed to the fully connected layer using the `view` method in PyTorch.
- The flattened tensor was then processed through a fully connected (dense) layer, known as the **Fully Connected Layer**. This layer was designed with two output neurons, corresponding to the two classes (presence or absence of nodules).
- Finally, a softmax function was applied to the output of the fully connected layer in the **Softmax Layer**. This step is standard for binary classification tasks, providing a probability distribution over the two classes.

The model was trained using the Adam optimizer, with a learning rate of 0.001, a batch size of 4, and a binary cross-entropy loss function. Training was conducted over 50 epochs, with early stopping and checkpointing based on the validation loss. The model parameters were initialized using He normal initialization, and the input scans were cropped to 128x128x128 voxels around the center of each scan. To increase the diversity of the training data, data augmentation techniques such as random rotation, scaling, flipping, and noise addition were applied.

To optimize the model, a grid search method was utilized to find the best combination of hyperparameters, including the number of filters, kernel size, dropout rate, and weight decay.

# Results
We obtained an accuracy of 99.78% on the validation set, which means that the model correctly predicted the class of 2703 out of 2709 nodules. However, when we looked at the confusion matrix, we found that the model predicted all the nodules as benign, and none as malignant. This means that the model had a recall of 0% for the malignant class, which means that it failed to identify any of the 6 malignant nodules in the validation set. This also means that the model had a precision of 0% for the malignant class, which means that none of its predictions for the malignant class were correct.

= Discussion

The main reason for this poor performance is the class imbalance problem in our dataset. The dataset has a very large imbalance between the benign and malignant classes, with the benign class being over 400 times more frequent than the malignant class. This makes it hard for the model to learn how to distinguish between the classes, and it might default to predicting the most common class. Moreover, because our dataset is highly imbalanced, accuracy is not a good measure of performance, as it can be misleadingly high even when the model makes incorrect predictions for the minority class.

To address this problem, we need to use a better strategy to train our model and also a better indication of model performance instead of accuracy. Some possible solutions are:

- Using data augmentation techniques to increase the number of malignant samples in our dataset.
- Using oversampling or undersampling methods to balance the classes in our dataset.
- Using weighted loss functions or class weights to penalize incorrect predictions for the minority class more than for the majority class.
- Using metrics such as F1-score, ROC-AUC, or PR-AUC that take into account both precision and recall for each class.

We plan to implement some of these solutions in our future work and hope to improve our model's performance on lung nodule classification.

# Conclusion

We presented a machine learning experiment where we attempted to classify lung nodules as benign or malignant based on CT scan images. We used a CNN model and trained it on a dataset of 10861 nodules, of which only 25 were malignant. We evaluated the model on a validation set of 2709 nodules, of which only 6 were malignant. We obtained an accuracy of 99.78%, but a recall of 0% for the malignant class. We discussed the reasons for this poor performance and suggested some possible solutions to address the class imbalance problem.
